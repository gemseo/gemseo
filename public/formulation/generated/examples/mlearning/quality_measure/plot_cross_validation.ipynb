{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nfrom matplotlib import pyplot as plt\nfrom numpy import array\nfrom numpy import linspace\nfrom numpy import newaxis\nfrom numpy import sin\n\nfrom gemseo.datasets.io_dataset import IODataset\nfrom gemseo.mlearning.regression.algos.polyreg import PolynomialRegressor\nfrom gemseo.mlearning.regression.quality.rmse_measure import RMSEMeasure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Every quality measure can be computed from a training dataset or a test dataset.\nThe use of a test dataset aims to\napproximate the quality of the machine learning model over the whole variable space\nin order to be less dependent on the training dataset\nand so to avoid over-fitting (accurate near learning points and poor elsewhere).\n\nIn the presence of expensive data,\nthis test dataset may just be a dream,\nand we have to estimate this quality with techniques resampling the training dataset,\nsuch as cross-validation.\nThe idea is simple:\nwe divide the training dataset into $K$ folds (typically 5),\niterate $K$ times the two-step task\n\"1) learn from $K-1$ folds, 2) predict from the remainder\"\nand finally approximate the measure from the $K$ batches of predictions.\n\nTo illustrate this point,\nlet us consider the function $f(x)=(6x-2)^2\\sin(12x-4)$.\n\n!!! quote \"References\"\n      Alexander I. J. Forrester, Andras Sobester, and Andy J. Keane.\n      Engineering design via surrogate modelling: a practical guide. Wiley, 2008.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def f(x):\n    return (6 * x - 2) ** 2 * sin(12 * x - 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and try to approximate it with a polynomial of order 3.\n\nFor this,\nwe can take these 7 learning input points\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_train = array([0.1, 0.3, 0.5, 0.6, 0.8, 0.9, 0.95])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and evaluate the model `f` over this design of experiments (DOE):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_train = f(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then,\nwe create an [IODataset][gemseo.datasets.io_dataset.IODataset] from these 7 learning samples:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_train = IODataset()\ndataset_train.add_input_group(x_train[:, newaxis], [\"x\"])\ndataset_train.add_output_group(y_train[:, newaxis], [\"y\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and build a [PolynomialRegressor][gemseo.mlearning.regression.algos.polyreg.PolynomialRegressor] with `degree=3` from it:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "polynomial = PolynomialRegressor(dataset_train, degree=3)\npolynomial.learn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now,\nwe compute the quality of this model with the RMSE metric:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rmse = RMSEMeasure(polynomial)\nrmse.compute_learning_measure()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As the cost of this academic function is zero,\nwe can approximate the generalization quality with a large test dataset\nwhereas the usual test size is about 20% of the training size.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_test = linspace(0.0, 1.0, 100)\ny_test = f(x_test)\ndataset_test = IODataset()\ndataset_test.add_input_group(x_test[:, newaxis], [\"x\"])\ndataset_test.add_output_group(y_test[:, newaxis], [\"y\"])\nrmse.compute_test_measure(dataset_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And do the same by cross-validation with $K=5$ folds\n(this number can be changed with the `n_folds` arguments):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rmse.compute_cross_validation_measure()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We note that the cross-validation error is pessimistic.\nAs the cross-validation method is based on randomization,\nwe can try again:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rmse.compute_cross_validation_measure()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result is even more pessimistic.\nWe can take a closer look by storing the sub-models:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rmse.compute_cross_validation_measure(store_resampling_result=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and plotting their outputs:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot = plt.plot(x_test, y_test, label=\"Reference\")\nplt.plot(x_train, y_train, \"o\", color=plot[0].get_color(), label=\"Training dataset\")\nplt.plot(x_test, polynomial.predict(x_test[:, newaxis]), label=\"Model\")\nfor i, algo in enumerate(polynomial.resampling_results[\"CrossValidation\"][1], 1):\n    plt.plot(x_test, algo.predict(x_test[:, newaxis]), label=f\"Sub-model {i}\")\nplt.legend()\nplt.grid()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that\nthis pessimistic error is mainly due to the fifth sub-model\nwhich did not learn the first training point\nand therefore has a very high extrapolation error.\n\nFinally,\nnote that we can make the result deterministic\nby using a custom seed\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result = rmse.compute_cross_validation_measure(seed=1)\nassert rmse.compute_cross_validation_measure(seed=1) == result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "or splitting the samples into $K$ folds\nwithout randomizing them\n(i.e. first samples in the first fold, next ones in the second, etc.):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result = rmse.compute_cross_validation_measure(randomize=False)\nassert rmse.compute_cross_validation_measure(randomize=False) == result"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
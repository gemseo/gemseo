{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gaussian process (GP) regression.\n\nA [GaussianProcessRegressor][gemseo.mlearning.regression.algos.gpr.GaussianProcessRegressor] is a GP regression model\nbased on [scikit-learn](https://scikit-learn.org).\n\n!!! info \"See also\"\n    You can find more information about building GP models with scikit-learn on\n    [this page](https://scikit-learn.org/stable/modules/gaussian_process.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nimport contextlib\n\nfrom matplotlib import pyplot as plt\nfrom numpy import array\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.gaussian_process.kernels import Matern\n\nfrom gemseo import create_design_space\nfrom gemseo import create_discipline\nfrom gemseo import sample_disciplines\nfrom gemseo.mlearning import create_regression_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem\n\nIn this example,\nwe represent the function $f(x)=(6x-2)^2\\sin(12x-4)$\nby the [AnalyticDiscipline][gemseo.disciplines.analytic.AnalyticDiscipline].\n\n!!! quote \"References\"\n      Alexander I. J. Forrester, Andras Sobester, and Andy J. Keane.\n      Engineering design via surrogate modelling: a practical guide. Wiley, 2008.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "discipline = create_discipline(\n    \"AnalyticDiscipline\",\n    name=\"f\",\n    expressions={\"y\": \"(6*x-2)**2*sin(12*x-4)\"},\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and seek to approximate it over the input space\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input_space = create_design_space()\ninput_space.add_variable(\"x\", lower_bound=0.0, upper_bound=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To do this,\nwe create a training dataset with 6 equispaced points:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "training_dataset = sample_disciplines(\n    [discipline], input_space, \"y\", algo_name=\"PYDOE_FULLFACT\", n_samples=6\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basics\n\n### Training\n\nThen,\nwe train a GP regression model from these samples:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = create_regression_model(\"GaussianProcessRegressor\", training_dataset)\nmodel.learn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prediction\n\nOnce it is built,\nwe can predict the output value of $f$ at a new input point:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input_value = {\"x\": array([0.65])}\noutput_value = model.predict(input_value)\noutput_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "but cannot predict its Jacobian value:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with contextlib.suppress(NotImplementedError):\n    model.predict_jacobian(input_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Uncertainty\n\nGP models are often valued for their ability to provide model uncertainty.\nIndeed,\na GP model is a random process fully characterized\nby its mean function\nand a covariance structure.\nGiven an input point $x$,\nthe prediction is equal to the mean at $x$\nand the uncertainty is equal to the standard deviation at $x$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "standard_deviation = model.predict_std(input_value)\nstandard_deviation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting\n\nYou can see that the GP model interpolates the training points\nbut is very bad elsewhere.\nThis case-dependent problem is due to poor auto-tuning of these length scales.\nWe will look at how to correct this next.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "test_dataset = sample_disciplines(\n    [discipline], input_space, \"y\", algo_name=\"PYDOE_FULLFACT\", n_samples=100\n)\ninput_data = test_dataset.get_view(variable_names=model.input_names).to_numpy()\nreference_output_data = test_dataset.get_view(variable_names=\"y\").to_numpy().ravel()\npredicted_output_data = model.predict(input_data).ravel()\nplt.plot(input_data.ravel(), reference_output_data, label=\"Reference\")\nplt.plot(input_data.ravel(), predicted_output_data, label=\"Regression - Basics\")\nplt.grid()\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Settings\n\nThe [GaussianProcessRegressor][gemseo.mlearning.regression.algos.gpr.GaussianProcessRegressor] has many options\ndefined in the [GaussianProcessRegressor_Settings][gemseo.mlearning.regression.algos.gpr_settings.GaussianProcessRegressor_Settings] Pydantic model.\nHere are the main ones.\n\n### Kernel\n\nThe `kernel` option defines the kernel function\nparametrizing the Gaussian process regressor\nand must be passed as a scikit-learn object.\nThe default kernel is the Mat\u00e9rn 5/2 covariance function\nwith input length scales belonging to the interval $[0.01,100]$,\ninitialized at 1\nand optimized by the L-BFGS-B algorithm.\nWe can replace this kernel by the Mat\u00e9rn 5/2 kernel\nwith input length scales fixed at 1:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = create_regression_model(\n    \"GaussianProcessRegressor\",\n    training_dataset,\n    kernel=Matern(length_scale=1.0, length_scale_bounds=\"fixed\", nu=2.5),\n)\nmodel.learn()\npredicted_output_data_1 = model.predict(input_data).ravel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "or a squared exponential covariance kernel\nwith input length scales fixed at 1:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = create_regression_model(\n    \"GaussianProcessRegressor\",\n    training_dataset,\n    kernel=RBF(length_scale=1.0, length_scale_bounds=\"fixed\"),\n)\nmodel.learn()\npredicted_output_data_2 = model.predict(input_data).ravel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These two models are much better than the previous one,\nnotably the one with the Mat\u00e9rn 5/2 kernel,\nwhich highlights that the concern with the initial model is\nthe value of the length scales found by numerical optimization:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.plot(input_data.ravel(), reference_output_data, label=\"Reference\")\nplt.plot(input_data.ravel(), predicted_output_data, label=\"Regression - Basics\")\nplt.plot(\n    input_data.ravel(), predicted_output_data_1, label=\"Regression - Kernel(Matern 2.5)\"\n)\nplt.plot(input_data.ravel(), predicted_output_data_2, label=\"Regression - Kernel(RBF)\")\nplt.grid()\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bounds\n\nThe `bounds` option defines the bounds of the input length scales;\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = create_regression_model(\n    \"GaussianProcessRegressor\", training_dataset, bounds=(1e-1, 1e2)\n)\nmodel.learn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Increasing the lower bounds can facilitate the training as in this example:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predicted_output_data_ = model.predict(input_data).ravel()\nplt.plot(input_data.ravel(), reference_output_data, label=\"Reference\")\nplt.plot(input_data.ravel(), predicted_output_data, label=\"Regression - Basics\")\nplt.plot(input_data.ravel(), predicted_output_data_, label=\"Regression - Bounds\")\nplt.grid()\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Alpha\n\nThe `alpha` parameter (default: 1e-10),\noften called *nugget effect*,\nis the value added to the diagonal of the training kernel matrix\nto avoid overfitting.\nWhen `alpha` is equal to zero,\nthe GP model interpolates the training points\nat which the standard deviation is equal to zero.\nThe larger `alpha` is, the less interpolating the GP model is.\nFor example, we can increase the value to 0.1:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predicted_output_data_1 = predicted_output_data_\nmodel = create_regression_model(\n    \"GaussianProcessRegressor\", training_dataset, bounds=(1e-1, 1e2), alpha=0.1\n)\nmodel.learn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and see that the model moves away from the training points:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predicted_output_data_2 = model.predict(input_data).ravel()\nplt.plot(input_data.ravel(), reference_output_data, label=\"Reference\")\nplt.plot(input_data.ravel(), predicted_output_data_1, label=\"Regression - Alpha(1e-10)\")\nplt.plot(input_data.ravel(), predicted_output_data_2, label=\"Regression - Alpha(1e-1)\")\nplt.grid()\nplt.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
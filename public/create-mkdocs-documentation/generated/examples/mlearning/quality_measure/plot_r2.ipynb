{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# R2 for regression models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nfrom matplotlib import pyplot as plt\nfrom numpy import array\nfrom numpy import linspace\nfrom numpy import newaxis\nfrom numpy import sin\n\nfrom gemseo.datasets.io_dataset import IODataset\nfrom gemseo.mlearning.regression.algos.polyreg import PolynomialRegressor\nfrom gemseo.mlearning.regression.algos.rbf import RBFRegressor\nfrom gemseo.mlearning.regression.quality.r2_measure import R2Measure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Given a dataset $(x_i,y_i,\\hat{y}_i)_{1\\leq i \\leq N}$\nwhere $x_i$ is an input point,\n$y_i$ is an output observation\nand $\\hat{y}_i=\\hat{f}(x_i)$ is an output prediction\ncomputed by a regression model $\\hat{f}$,\nthe $R^2$ metric (also known as $Q^2$) is written\n\n$$R^2 = 1 - \\frac{\\sum_{i=1}^N(y_i-\\hat{y}_i)^2}{\\sum_{i=1}^N(y_i-\\bar{y})^2} \\leq 1$$\n\nwhere $\\bar{y}=\\frac{1}{N}\\sum_{i=1}^Ny_i$.\nThe higher, the better.\nFrom 0.9 it starts to look (very) good.\nA negative value is very bad; a constant model would do better.\n\nTo illustrate this quality measure,\nlet us consider the function $f(x)=(6x-2)^2\\sin(12x-4)$.\n\n!!! quote \"References\"\n      Alexander I. J. Forrester, Andras Sobester, and Andy J. Keane.\n      Engineering design via surrogate modelling: a practical guide. Wiley, 2008.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def f(x):\n    return (6 * x - 2) ** 2 * sin(12 * x - 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and try to approximate it with a polynomial of order 3.\n\nFor this,\nwe can take these 7 learning input points\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_train = array([0.1, 0.3, 0.5, 0.6, 0.8, 0.9, 0.95])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and evaluate the model `f` over this design of experiments (DOE):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_train = f(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then,\nwe create an [IODataset][gemseo.datasets.io_dataset.IODataset] from these 7 learning samples:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_train = IODataset()\ndataset_train.add_input_group(x_train[:, newaxis], [\"x\"])\ndataset_train.add_output_group(y_train[:, newaxis], [\"y\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and build a [PolynomialRegressor][gemseo.mlearning.regression.algos.polyreg.PolynomialRegressor] with `degree=3` from it:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "polynomial = PolynomialRegressor(dataset_train, degree=3)\npolynomial.learn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before using it,\nwe are going to measure its quality with the $R^2$ metric:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "r2 = R2Measure(polynomial)\nr2.compute_learning_measure()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This result is medium, and we can be expected to a poor generalization quality.\nAs the cost of this academic function is zero,\nwe can approximate this generalization quality with a large test dataset\nwhereas the usual test size is about 20% of the training size.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_test = linspace(0.0, 1.0, 100)\ny_test = f(x_test)\ndataset_test = IODataset()\ndataset_test.add_input_group(x_test[:, newaxis], [\"x\"])\ndataset_test.add_output_group(y_test[:, newaxis], [\"y\"])\nr2.compute_test_measure(dataset_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The quality is lower than 0.5, which is pretty mediocre.\nThis can be explained by a broader generalization domain\nthan that of learning, which highlights the difficulties of extrapolation:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.plot(x_test, y_test, \"-b\", label=\"Reference\")\nplt.plot(x_train, y_train, \"ob\")\nplt.plot(x_test, polynomial.predict(x_test[:, newaxis]), \"-r\", label=\"Prediction\")\nplt.plot(x_train, polynomial.predict(x_train[:, newaxis]), \"or\")\nplt.legend()\nplt.grid()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the learning domain would slightly improve the quality:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_test = linspace(x_train.min(), x_train.max(), 100)\ny_test = f(x_test)\ndataset_test_in_learning_domain = IODataset()\ndataset_test_in_learning_domain.add_input_group(x_test[:, newaxis], [\"x\"])\ndataset_test_in_learning_domain.add_output_group(y_test[:, newaxis], [\"y\"])\nr2.compute_test_measure(dataset_test_in_learning_domain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lastly,\nto get better results without new learning points,\nwe would have to change the regression model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rbf = RBFRegressor(dataset_train)\nrbf.learn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The quality of this [RBFRegressor][gemseo.mlearning.regression.algos.rbf.RBFRegressor] is quite good,\nboth on the learning side:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "r2_rbf = R2Measure(rbf)\nr2_rbf.compute_learning_measure()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and on the validation side:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "r2_rbf.compute_test_measure(dataset_test_in_learning_domain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "including the larger domain:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "r2_rbf.compute_test_measure(dataset_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A final plot to convince us:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.plot(x_test, y_test, \"-b\", label=\"Reference\")\nplt.plot(x_train, y_train, \"ob\")\nplt.plot(x_test, rbf.predict(x_test[:, newaxis]), \"-r\", label=\"Prediction\")\nplt.plot(x_train, rbf.predict(x_train[:, newaxis]), \"or\")\nplt.legend()\nplt.grid()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
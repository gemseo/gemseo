{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RMSE for regression models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nfrom matplotlib import pyplot as plt\nfrom numpy import array\nfrom numpy import linspace\nfrom numpy import newaxis\nfrom numpy import sin\n\nfrom gemseo.datasets.io_dataset import IODataset\nfrom gemseo.mlearning.regression.algos.polyreg import PolynomialRegressor\nfrom gemseo.mlearning.regression.algos.rbf import RBFRegressor\nfrom gemseo.mlearning.regression.quality.rmse_measure import RMSEMeasure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Given a dataset $(x_i,y_i,\\hat{y}_i)_{1\\leq i \\leq N}$\nwhere $x_i$ is an input point,\n$y_i$ is an output observation\nand $\\hat{y}_i=\\hat{f}(x_i)$ is an output prediction\ncomputed by a regression model $\\hat{f}$,\nthe root mean squared error (RMSE) metric is written\n\n$$\\text{RMSE} = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N(y_i-\\hat{y}_i)^2} \\geq 0.$$\n\nThe lower, the better.\nFrom a quantitative point of view,\nthis depends on the order of magnitude of the outputs.\n\nTo illustrate this quality measure,\nlet us consider the function $f(x)=(6x-2)^2\\sin(12x-4)$ .\n\n!!! quote \"References\"\n      Alexander I. J. Forrester, Andras Sobester, and Andy J. Keane.\n      Engineering design via surrogate modelling: a practical guide. Wiley, 2008.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def f(x):\n    return (6 * x - 2) ** 2 * sin(12 * x - 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and try to approximate it with a polynomial of order 3.\n\nFor this,\nwe can take these 7 learning input points\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_train = array([0.1, 0.3, 0.5, 0.6, 0.8, 0.9, 0.95])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and evaluate the model `f` over this design of experiments (DOE):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_train = f(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then,\nwe create an [IODataset][gemseo.datasets.io_dataset.IODataset] from these 7 learning samples:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_train = IODataset()\ndataset_train.add_input_group(x_train[:, newaxis], [\"x\"])\ndataset_train.add_output_group(y_train[:, newaxis], [\"y\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and build a [PolynomialRegressor][gemseo.mlearning.regression.algos.polyreg.PolynomialRegressor] with `degree=3` from it:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "polynomial = PolynomialRegressor(dataset_train, degree=3)\npolynomial.learn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before using it,\nwe are going to measure its quality with the RMSE metric:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rmse = RMSEMeasure(polynomial)\nresult = rmse.compute_learning_measure()\nresult, result / (y_train.max() - y_train.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This result is medium (14% of the learning output range),\nand we can be expected to a poor generalization quality.\nAs the cost of this academic function is zero,\nwe can approximate this generalization quality with a large test dataset\nwhereas the usual test size is about 20% of the training size.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_test = linspace(0.0, 1.0, 100)\ny_test = f(x_test)\ndataset_test = IODataset()\ndataset_test.add_input_group(x_test[:, newaxis], [\"x\"])\ndataset_test.add_output_group(y_test[:, newaxis], [\"y\"])\nresult = rmse.compute_test_measure(dataset_test)\nresult, result / (y_test.max() - y_test.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The quality is higher than 15% of the test output range, which is pretty mediocre.\nThis can be explained by a broader generalization domain\nthan that of learning, which highlights the difficulties of extrapolation:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.plot(x_test, y_test, \"-b\", label=\"Reference\")\nplt.plot(x_train, y_train, \"ob\")\nplt.plot(x_test, polynomial.predict(x_test[:, newaxis]), \"-r\", label=\"Prediction\")\nplt.plot(x_train, polynomial.predict(x_train[:, newaxis]), \"or\")\nplt.legend()\nplt.grid()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the learning domain would slightly improve the quality:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_test = linspace(x_train.min(), x_train.max(), 100)\ny_test_in_large_domain = y_test\ny_test = f(x_test)\ndataset_test_in_learning_domain = IODataset()\ndataset_test_in_learning_domain.add_input_group(x_test[:, newaxis], [\"x\"])\ndataset_test_in_learning_domain.add_output_group(y_test[:, newaxis], [\"y\"])\nresult = rmse.compute_test_measure(dataset_test_in_learning_domain)\nresult, result / (y_test.max() - y_test.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lastly,\nto get better results without new learning points,\nwe would have to change the regression model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rbf = RBFRegressor(dataset_train)\nrbf.learn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The quality of this [RBFRegressor][gemseo.mlearning.regression.algos.rbf.RBFRegressor] is quite good,\nboth on the learning side:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rmse_rbf = RMSEMeasure(rbf)\nresult = rmse_rbf.compute_learning_measure()\nresult, result / (y_train.max() - y_train.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and on the validation side:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result = rmse_rbf.compute_test_measure(dataset_test_in_learning_domain)\nresult, result / (y_test.max() - y_test.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "including the larger domain:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result = rmse_rbf.compute_test_measure(dataset_test)\nresult, result / (y_test_in_large_domain.max() - y_test_in_large_domain.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A final plot to convince us:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.plot(x_test, y_test, \"-b\", label=\"Reference\")\nplt.plot(x_train, y_train, \"ob\")\nplt.plot(x_test, rbf.predict(x_test[:, newaxis]), \"-r\", label=\"Prediction\")\nplt.plot(x_train, rbf.predict(x_train[:, newaxis]), \"or\")\nplt.legend()\nplt.grid()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
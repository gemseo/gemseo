{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced mixture of experts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nfrom gemseo import create_benchmark_dataset\nfrom gemseo.mlearning import create_regression_model\nfrom gemseo.mlearning.classification.quality.f1_measure import F1Measure\nfrom gemseo.mlearning.clustering.quality.silhouette_measure import SilhouetteMeasure\nfrom gemseo.mlearning.regression.quality.mse_measure import MSEMeasure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example,\nwe seek to estimate the Rosenbrock function\nusing the function [create_benchmark_dataset][gemseo.create_benchmark_dataset]\nfor generating the datasets.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = create_benchmark_dataset(\"RosenbrockDataset\", opt_naming=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For that purpose,\nwe will use an [MOERegressor][gemseo.mlearning.regression.algos.moe.MOERegressor] in an advanced way:\nwe will not set the clustering, classification and regression algorithms\nbut select them according to their performance\nfrom several candidates that we will provide.\nMoreover,\nfor a given candidate,\nwe will propose several settings,\ncompare their performances\nand select the best one.\n\n## Initialization\n\nFirst,\nwe initialize an [MOERegressor][gemseo.mlearning.regression.algos.moe.MOERegressor] with soft classification\nby means of the high-level machine learning function [create_regression_model()][gemseo.mlearning.create_regression_model].\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = create_regression_model(\"MOERegressor\", dataset, hard=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clustering\n\nThen,\nwe add two clustering algorithms\nwith different numbers of clusters (called *components* for the Gaussian Mixture)\nand set the [SilhouetteMeasure][gemseo.mlearning.clustering.quality.silhouette_measure.SilhouetteMeasure] as clustering measure\nto be evaluated from the training dataset.\nDuring the learning stage,\nthe mixture of experts will select the clustering algorithm\nand the number of clusters\nminimizing this measure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model.set_clustering_measure(SilhouetteMeasure)\nmodel.add_clusterer_candidate(\"KMeans\", n_clusters=[2, 3, 4])\nmodel.add_clusterer_candidate(\"GaussianMixture\", n_clusters=[3, 4, 5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification\n\nWe also add classification algorithms\nwith different settings\nand set the [F1Measure][gemseo.mlearning.classification.quality.f1_measure.F1Measure] as classification measure\nto be evaluated from the training dataset.\nDuring the learning stage,\nthe mixture of experts will select the classification algorithm and the settings\nminimizing this measure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model.set_classification_measure(F1Measure)\nmodel.add_classifier_candidate(\"KNNClassifier\", n_neighbors=[3, 4, 5])\nmodel.add_classifier_candidate(\"RandomForestClassifier\", n_estimators=[100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regression\n\nWe also add regression algorithms\nand set the [MSEMeasure][gemseo.mlearning.regression.quality.mse_measure.MSEMeasure] as regression measure\nto be evaluated from the training dataset.\nDuring the learning stage, for each cluster,\nthe mixture of experts will select the regression algorithm minimizing this measure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model.set_regression_measure(MSEMeasure)\nmodel.add_regressor_candidate(\"LinearRegressor\")\nmodel.add_regressor_candidate(\"RBFRegressor\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!!! note\n\n    We could also add candidates for some learning stages,\n    e.g. clustering and regression,\n    and set the machine learning algorithms for the remaining ones,\n    e.g. classification.\n\n## Training\n\nLastly,\nwe learn the data\nand select the best machine learning algorithm\nfor both clustering, classification and regression steps.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model.learn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Result\n\nWe can get information on this model,\non the sub-machine learning models selected among the candidates\nand on their selected settings.\nWe can see that\na [MKeans][gemseo.mlearning.clustering.algos.kmeans.KMeans] with four clusters has been selected for the clustering stage,\nas well as a [RandomForestClassifier][gemseo.mlearning.classification.algos.random_forest.RandomForestClassifier] for the classification stage\nand a [RBFRegressor][gemseo.mlearning.regression.algos.rbf.RBFRegressor] for each cluster.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!!! note\n\n    By adding candidates,\n    and depending on the complexity of the function to be approximated,\n    one could obtain different regression models according to the clusters.\n    For example,\n    one could use a [PolynomialRegressor][gemseo.mlearning.regression.algos.polyreg.PolynomialRegressor] with order 2\n    on a sub-part of the input space\n    and a [GaussianProcessRegressor][gemseo.mlearning.regression.algos.gpr.GaussianProcessRegressor]\n    on another sub-part of the input space.\n\nOnce built,\nthis mixture of experts can be used as any [BaseRegressor][gemseo.mlearning.regression.algos.base_regressor.BaseRegressor].\n\n!!! info \"See also\"\n\n    [Another example][mixture-of-experts]\n    proposes a standard use of [MOERegressor][gemseo.mlearning.regression.algos.moe.MOERegressor].\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
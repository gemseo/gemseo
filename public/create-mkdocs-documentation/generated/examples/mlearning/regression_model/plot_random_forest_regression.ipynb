{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Random forest.\n\nA [RandomForestRegressor][gemseo.mlearning.regression.algos.random_forest.RandomForestRegressor] is a random forest model\nbased on [scikit-learn](https://scikit-learn.org).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nimport contextlib\n\nfrom matplotlib import pyplot as plt\nfrom numpy import array\n\nfrom gemseo import create_design_space\nfrom gemseo import create_discipline\nfrom gemseo import sample_disciplines\nfrom gemseo.mlearning import create_regression_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem\n\nIn this example,\nwe represent the function $f(x)=(6x-2)^2\\sin(12x-4)$\nby the [AnalyticDiscipline][gemseo.disciplines.analytic.AnalyticDiscipline].\n\n!!! quote \"References\"\n      Alexander I. J. Forrester, Andras Sobester, and Andy J. Keane.\n      Engineering design via surrogate modelling: a practical guide. Wiley, 2008.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "discipline = create_discipline(\n    \"AnalyticDiscipline\",\n    name=\"f\",\n    expressions={\"y\": \"(6*x-2)**2*sin(12*x-4)\"},\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and seek to approximate it over the input space\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input_space = create_design_space()\ninput_space.add_variable(\"x\", lower_bound=0.0, upper_bound=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To do this,\nwe create a training dataset with 6 equispaced points:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "training_dataset = sample_disciplines(\n    [discipline], input_space, \"y\", algo_name=\"PYDOE_FULLFACT\", n_samples=6\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basics\n\n### Training\n\nThen,\nwe train an random forest regression model from these samples:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = create_regression_model(\"RandomForestRegressor\", training_dataset)\nmodel.learn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prediction\n\nOnce it is built,\nwe can predict the output value of $f$ at a new input point:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input_value = {\"x\": array([0.65])}\noutput_value = model.predict(input_value)\noutput_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "but cannot predict its Jacobian value:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with contextlib.suppress(NotImplementedError):\n    model.predict_jacobian(input_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting\n\nYou can see that the random forest model is pretty good on the left,\nbut bad on the right:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "test_dataset = sample_disciplines(\n    [discipline], input_space, \"y\", algo_name=\"PYDOE_FULLFACT\", n_samples=100\n)\ninput_data = test_dataset.get_view(variable_names=model.input_names).to_numpy()\nreference_output_data = test_dataset.get_view(variable_names=\"y\").to_numpy().ravel()\npredicted_output_data = model.predict(input_data).ravel()\nplt.plot(input_data.ravel(), reference_output_data, label=\"Reference\")\nplt.plot(input_data.ravel(), predicted_output_data, label=\"Regression - Basics\")\nplt.grid()\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Settings\n\n### Number of estimators\n\nThe main hyperparameter of random forest regression is\nthe number of trees in the forest (default: 100).\nHere is a comparison when increasing and decreasing this number:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = create_regression_model(\n    \"RandomForestRegressor\", training_dataset, n_estimators=10\n)\nmodel.learn()\npredicted_output_data_1 = model.predict(input_data).ravel()\nmodel = create_regression_model(\n    \"RandomForestRegressor\", training_dataset, n_estimators=1000\n)\nmodel.learn()\npredicted_output_data_2 = model.predict(input_data).ravel()\nplt.plot(input_data.ravel(), reference_output_data, label=\"Reference\")\nplt.plot(input_data.ravel(), predicted_output_data, label=\"Regression - Basics\")\nplt.plot(input_data.ravel(), predicted_output_data_1, label=\"Regression - 10 trees\")\nplt.plot(input_data.ravel(), predicted_output_data_2, label=\"Regression - 1000 trees\")\nplt.grid()\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Others\n\nThe `RandomForestRegressor` class of scikit-learn has a lot of settings\n([read more](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)),\nand we have chosen to exhibit only `n_estimators`.\nHowever,\nany argument of `RandomForestRegressor` can be set\nusing the dictionary `parameters`.\nFor example,\nwe can impose a minimum of two samples per leaf:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = create_regression_model(\n    \"RandomForestRegressor\", training_dataset, parameters={\"min_samples_leaf\": 2}\n)\nmodel.learn()\npredicted_output_data_ = model.predict(input_data).ravel()\nplt.plot(input_data.ravel(), reference_output_data, label=\"Reference\")\nplt.plot(input_data.ravel(), predicted_output_data, label=\"Regression - Basics\")\nplt.plot(input_data.ravel(), predicted_output_data_, label=\"Regression - 2 samples\")\nplt.grid()\nplt.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}